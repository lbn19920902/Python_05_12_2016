import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.decomposition import *
from sklearn.preprocessing import OneHotEncoder
from sklearn.cross_validation import train_test_split
from sklearn.utils import shuffle
import xgboost as xgb
from sklearn.feature_extraction import DictVectorizer

train_cols=train.columns
test_cols=test.columns
labels=np.array(train.Hazard).ravel()
train_ids=np.array(train.Id).ravel()
test_ids=np.array(test.Id).ravel()

train.drop('Id',axis=1,inplace=True)
train.drop('Hazard',axis=1,inplace=True)
test.drop('Id',axis=1,inplace=True)

train=np.array(train)
test=np.array(test)

for i in range(train.shape[1]):
    lbl=preprocessing.LabelEncoder()
    lbl.fit(list(train[:,i])+list(test[:,i]))
    train[:,i]=lbl.transform(train[:,i])
    test[:,i]=lbl.transform(train[:,i])

train=np.column_stack((train_ids,labels,train))
test=np.column_stack((test_ids,test))

train=pd.DataFrame(train,columns=train_cols)
test=pd.DateFrame(test,columns=test_cols)

train['Id']=train['Id'].astype(int)
train['Hazard']=train['Hazard'].astype(int)
test['Id']=test['Id'].astype(int)


